{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLyGGNWqob-I"
      },
      "source": [
        "*mounting to google drive*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14DYKVj3CBiT",
        "outputId": "e69f9b0e-6336-4826-d022-dd8f404b0e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkl_cXdPogPo"
      },
      "source": [
        "*install library prerequisites*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrL3tlE5ECcu",
        "outputId": "c170e15d-acf6-42ca-b7cc-0faea5cbda94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy scikit-learn pillow tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0AFVwpEDihG"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "xLf-xgi9rm5K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from tensorflow.keras.preprocessing.image import (ImageDataGenerator, img_to_array,\n",
        "                                               load_img)\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Juv9iwQ5Bi-o"
      },
      "source": [
        "#Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "b_EYvFlPCrIR"
      },
      "outputs": [],
      "source": [
        "# --------------------- Configuration ---------------------\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "DATA_DIR = r\"/content/drive/My Drive/ASL_to_Text_Project/data\"\n",
        "IMAGES_DIR = os.path.join(DATA_DIR, 'images')\n",
        "MODEL_DIR = r\"/content/drive/My Drive/ASL_to_Text_Project/models\"\n",
        "LABELS_DIR = r\"/content/drive/My Drive/ASL_to_Text_Project/data/labels\"\n",
        "# --------------------- Configuration ---------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zydXBpseyKVs"
      },
      "source": [
        "# script for finding the folders in drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCD4vP7dZ_jK",
        "outputId": "05ddc04f-5f61-437d-fdf1-e2e1f6b79d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Directory not found: /content/drive/MyDrive/ASL/ASL_to_Text_Project\n",
            "Please ensure the path is correct and the drive is mounted.\n"
          ]
        }
      ],
      "source": [
        "project_dir = '/content/drive/MyDrive/ASL/ASL_to_Text_Project'\n",
        "if os.path.exists(project_dir):\n",
        "  print(f\"\\nContents of {project_dir}:\")\n",
        "  print(os.listdir(project_dir))\n",
        "else:\n",
        "  print(f\"Error: Directory not found: {project_dir}\")\n",
        "  print(\"Please ensure the path is correct and the drive is mounted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0aja5eyLH2u"
      },
      "source": [
        "#Directory tweaks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "-WdeEKk5JQNr"
      },
      "outputs": [],
      "source": [
        "# Create directories if they don't exist\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(LABELS_DIR, exist_ok=True)\n",
        "os.makedirs(IMAGES_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_2fVjBfDqzn"
      },
      "source": [
        "#mobilenet model Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "LF0VbvihAj43"
      },
      "outputs": [],
      "source": [
        "def create_mobilenetv2_model(num_classes, input_shape=(IMG_SIZE, IMG_SIZE, 3)):\n",
        "    \"\"\"Enhanced MobileNetV2 model with improved anti-overfitting techniques\"\"\"\n",
        "    # Base model configuration\n",
        "    base_model = tf.keras.applications.MobileNetV2(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=input_shape\n",
        "    )\n",
        "\n",
        "    # Selectively unfreeze more layers for fine-tuning\n",
        "    for layer in base_model.layers[:-30]:\n",
        "        layer.trainable = False\n",
        "    for layer in base_model.layers[-30:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    x = base_model.output\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Enhanced regularization\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dense(\n",
        "        512,\n",
        "        activation='relu',\n",
        "        kernel_regularizer=regularizers.l2(0.005),  # Slightly adjusted regularization\n",
        "        activity_regularizer=regularizers.l1(0.0001)\n",
        "    )(x)\n",
        "    x = tf.keras.layers.Dropout(0.6)(x)  # Increased dropout\n",
        "\n",
        "    # Output layer with stronger regularization\n",
        "    outputs = tf.keras.layers.Dense(\n",
        "        num_classes,\n",
        "        activation='softmax',\n",
        "        kernel_regularizer=regularizers.l1_l2(l1=0.003, l2=0.01)\n",
        "    )(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=base_model.input, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98DGeJSWDvLe"
      },
      "source": [
        "#Loading and Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "m_gO8Wd0AmvG"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "def load_data(data_dir, allowed_extensions=('.jpg', '.jpeg', '.png', '.gif', '.bmp')):\n",
        "    \"\"\"Loads images and their corresponding labels.\"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    for label in os.listdir(data_dir):\n",
        "        if label.startswith('.'):\n",
        "            continue\n",
        "        label_dir = os.path.join(data_dir, label)\n",
        "        if os.path.isdir(label_dir):\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                if img_name.startswith('.'):\n",
        "                    continue\n",
        "                if not img_name.lower().endswith(allowed_extensions):\n",
        "                    print(f\"Skipping unsupported file: {img_name}\")\n",
        "                    continue\n",
        "                try:\n",
        "                    img_path = os.path.join(label_dir, img_name)\n",
        "                    img = Image.open(img_path)\n",
        "                    img.verify()\n",
        "                    img = load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "                    img_array = img_to_array(img)\n",
        "                    images.append(img_array)\n",
        "                    labels.append(label)\n",
        "                except (IOError, UnidentifiedImageError) as e:\n",
        "                    print(f\"Error loading image {img_name}: {e}\")\n",
        "                    continue\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW8bFm9nb4qv"
      },
      "source": [
        "#training history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "T9A7Wkwab36p"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training history with improved styling.\"\"\"\n",
        "    sns.set_theme()\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Plot loss\n",
        "    ax1.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
        "    ax1.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "    ax1.set_title('Training and Validation Loss', fontsize=12, pad=15)\n",
        "    ax1.set_xlabel('Epoch', fontsize=10)\n",
        "    ax1.set_ylabel('Loss', fontsize=10)\n",
        "    ax1.legend(frameon=True)\n",
        "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Plot accuracy\n",
        "    ax2.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
        "    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
        "    ax2.set_title('Training and Validation Accuracy', fontsize=12, pad=15)\n",
        "    ax2.set_xlabel('Epoch', fontsize=10)\n",
        "    ax2.set_ylabel('Accuracy', fontsize=10)\n",
        "    ax2.legend(frameon=True)\n",
        "    ax2.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes):\n",
        "    \"\"\"Plot confusion matrix with improved visualization.\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=classes, yticklabels=classes)\n",
        "    plt.title('Confusion Matrix', fontsize=12, pad=15)\n",
        "    plt.xlabel('Predicted Label', fontsize=10)\n",
        "    plt.ylabel('True Label', fontsize=10)\n",
        "    plt.tight_layout()\n",
        "    return plt.gcf()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#learning rate scheduler"
      ],
      "metadata": {
        "id": "HQvseOSlqh9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def learning_rate_scheduler(epoch, lr):\n",
        "    \"\"\"Learning rate scheduler function.\n",
        "\n",
        "    Args:\n",
        "        epoch (int): Current epoch number.\n",
        "        lr (float): Current learning rate.\n",
        "\n",
        "    Returns:\n",
        "        float: New learning rate.\n",
        "    \"\"\"\n",
        "    if epoch < 10:\n",
        "        return float(lr)  # Explicitly convert to float\n",
        "    else:\n",
        "        return float(lr * np.exp(-0.1))"
      ],
      "metadata": {
        "id": "ZMgvazr_qhx9"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meGcA_IZdTO9"
      },
      "source": [
        "# analyze model performance / calculations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "YIOyM5LFdQtd"
      },
      "outputs": [],
      "source": [
        "def analyze_model_performance(model, history, X_test, y_test, le, X_train, EPOCHS):\n",
        "    \"\"\"Analyze and visualize model performance.\"\"\"\n",
        "    # Calculate total images trained\n",
        "    total_images_trained = len(X_train) * EPOCHS\n",
        "    print(f\"\\nTraining Summary:\")\n",
        "    print(f\"Total Images Trained On: {total_images_trained:,}\")\n",
        "    print(f\"Number of Epochs: {EPOCHS}\")\n",
        "    print(f\"Training Set Size: {len(X_train):,} images\")\n",
        "    print(f\"Test Set Size: {len(X_test):,} images\")\n",
        "\n",
        "    # Plot training history\n",
        "    history_fig = plot_training_history(history)\n",
        "    history_fig.savefig(os.path.join(MODEL_DIR, 'training_history.png'))\n",
        "\n",
        "    # Get predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    cm_fig = plot_confusion_matrix(y_test_classes, y_pred_classes, le.classes_)\n",
        "    cm_fig.savefig(os.path.join(MODEL_DIR, 'confusion_matrix.png'))\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_test_classes, y_pred_classes,\n",
        "                                 target_names=le.classes_,\n",
        "                                 output_dict=True)\n",
        "\n",
        "    # Save training metrics and classification report\n",
        "    with open(os.path.join(MODEL_DIR, 'training_report.txt'), 'w') as f:\n",
        "        f.write(\"Training Metrics:\\n\")\n",
        "        f.write(f\"Total Images Trained On: {total_images_trained:,}\\n\")\n",
        "        f.write(f\"Number of Epochs: {EPOCHS}\\n\")\n",
        "        f.write(f\"Training Set Size: {len(X_train):,} images\\n\")\n",
        "        f.write(f\"Test Set Size: {len(X_test):,} images\\n\\n\")\n",
        "        f.write(\"Classification Report:\\n\")\n",
        "        for label in report:\n",
        "            if label not in ['accuracy', 'macro avg', 'weighted avg']:\n",
        "                f.write(f\"\\nClass: {label}\\n\")\n",
        "                f.write(f\"Precision: {report[label]['precision']:.3f}\\n\")\n",
        "                f.write(f\"Recall: {report[label]['recall']:.3f}\\n\")\n",
        "                f.write(f\"F1-Score: {report[label]['f1-score']:.3f}\\n\")\n",
        "                f.write(f\"Support: {report[label]['support']}\\n\")\n",
        "\n",
        "    return report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLAHXQyVAq9o"
      },
      "source": [
        "# **MAIN EXECUTION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_9c467oD3JY"
      },
      "source": [
        "#load ang preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeVKdR6rAo96",
        "outputId": "e0d667d9-970a-4879-f045-92009fca1295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images loaded: 8153\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, y = load_data(IMAGES_DIR)\n",
        "print(f\"Number of images loaded: {len(X)}\")\n",
        "X = X / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo09K0_lEGe8"
      },
      "source": [
        "#Encode Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoKES3vjAy75",
        "outputId": "0f796ad7-cdb8-44f5-b3db-7bc010481ad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Classes : 27\n"
          ]
        }
      ],
      "source": [
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "num_classes = len(le.classes_)\n",
        "print(f\"Number of Classes : {num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3etnSCwGEIGb"
      },
      "source": [
        "#Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "b6iPk3IZA1Hv"
      },
      "outputs": [],
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "husLB4_oEKO3"
      },
      "source": [
        "#Convert to categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "UDr49WcQA4kN"
      },
      "outputs": [],
      "source": [
        "# Convert to categorical\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn_ffKKmENiC"
      },
      "source": [
        "#Model Creation and Compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "boHTjDAtA54l"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create and compile model\n",
        "model = create_mobilenetv2_model(num_classes)\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4HnWLlTEQ0P"
      },
      "source": [
        "#Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "sV7axn9OA7BQ"
      },
      "outputs": [],
      "source": [
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.15,\n",
        "    shear_range=0.1,\n",
        "    fill_mode=\"nearest\",\n",
        "    brightness_range=[0.9, 1.1]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5uzpOs6ES3e"
      },
      "source": [
        "#Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "1RHV3h5VA8dT"
      },
      "outputs": [],
      "source": [
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pMZmcB9A_lS"
      },
      "source": [
        "# Model Trainig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu3aLJKUA-af",
        "outputId": "bf8f950f-4e96-4e51-876a-07ca3805960f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 404ms/step - accuracy: 0.0622 - loss: 12.0031 - val_accuracy: 0.0429 - val_loss: 10.8760 - learning_rate: 1.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m  1/203\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.0625 - loss: 10.1060"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0625 - loss: 10.1060 - val_accuracy: 0.0423 - val_loss: 10.8699 - learning_rate: 1.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m144/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 358ms/step - accuracy: 0.1464 - loss: 10.0686"
          ]
        }
      ],
      "source": [
        "# Update the training process in the main script\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(learning_rate_scheduler)\n",
        "\n",
        "\n",
        "# Flatten y_train before applying np.unique to get unique class labels\n",
        "unique_classes = np.unique(y_train.flatten())\n",
        "class_weights = compute_class_weight('balanced', classes=unique_classes, y=y_train.flatten())\n",
        "\n",
        "# Convert the class weights to a dictionary\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Add ReduceLROnPlateau callback\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "# Modify model.fit() callbacks to include new learning rate management\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
        "    steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            filepath=os.path.join(MODEL_DIR, \"asl_mobilenetv2_model_{epoch:02d}_{val_accuracy:.2f}.keras\"),\n",
        "            monitor=\"val_accuracy\",\n",
        "            save_best_only=True,\n",
        "            mode=\"max\",\n",
        "        ),\n",
        "        early_stopping,\n",
        "        lr_schedule,\n",
        "        reduce_lr\n",
        "    ],\n",
        "    class_weight=class_weight_dict\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vYs6YTyEYqw"
      },
      "source": [
        "#Dataset Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfnoF4jxBCaA"
      },
      "outputs": [],
      "source": [
        "# Evaluate on the test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxMOMjB8Ebsi"
      },
      "source": [
        "#Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fr-UagoJBEfU"
      },
      "outputs": [],
      "source": [
        "# Save the entire model\n",
        "model.save(os.path.join(MODEL_DIR, \"asl_mobilenetv2_model.h5\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqYX4ZIqEeUu"
      },
      "source": [
        "#Save label encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsLuHICXluZW"
      },
      "outputs": [],
      "source": [
        "# Save the label encoder\n",
        "with open(os.path.join(LABELS_DIR, 'cnn_label_encoder.pkl'), 'wb') as f:\n",
        "    pickle.dump(le, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxPAWIg-Khw8"
      },
      "source": [
        "# Plot Training and Validation curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4TMZ2HZbsdS"
      },
      "outputs": [],
      "source": [
        "# Analyze model performance\n",
        "print(\"\\nAnalyzing model performance...\")\n",
        "performance_report = analyze_model_performance(model, history, X_test, y_test, le, X_train, EPOCHS)\n",
        "print(\"\\nAnalysis complete! Check the model directory for visualization plots and detailed reports.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}